select_dtypes

If data preprocessing has to be done in Python, then this command would save you some time. After reading in a table, the default data types for each column could be bool, int64, float64, object, category, timedelta64, or datetime64. You can first check the distribution by
df.dtypes.value_counts()
to know all possible data types of your dataframe, then do
df.select_dtypes(include=['float64', 'int64'])





value counts
This is a command to check value distributions. 
For example, if you’d like to check what are the possible values and the frequency for each individual value in column ‘c’ you can do
df['c'].value_counts()

There’re some useful tricks / arguments of it:
A. normalize = True: if you want to check the frequency instead of counts.
B. dropna = False: if you also want to include missing values in the stats.
C. df['c'].value_counts().reset_index(): if you want to convert the stats table into a pandas dataframe and manipulate it
D. df['c'].value_counts().reset_index().sort_values(by='index') : 

show the stats sorted by distinct values in column ‘c’ instead of counts.
(Update 2019.4.18 — for D. above, Hao Yang points out a simpler way without .reset_index(): df['c'].value_counts().sort_index())
